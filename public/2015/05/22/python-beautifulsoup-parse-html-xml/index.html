<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="豪翔天下的博客,haoflynet,haofly"><title>Python使用beautifulsoup解析HTML、XML | 豪翔天下</title><link rel="stylesheet" type="text/css" href="/css/normalize.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="/css/pure-min.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="/css/grids-responsive-min.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Python使用beautifulsoup解析HTML、XML</h1><a id="logo" href="/.">豪翔天下</a><p class="description">Change My World by Program</p></div><div id="nav-menu"><a href="/." class="current"><i class="icon-home"> 首页</i></a><a href="/archives/"><i class="icon-archive"> 归档</i></a><a href="/about/"><i class="icon-about"> 关于</i></a><a href="/atom.xml"><i class="icon-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post post-page"><h1 class="post-title">Python使用beautifulsoup解析HTML、XML</h1><div class="post-meta">2015-05-22<span class="categories"> | 分类于<a href="/categories/编程之路/"> 编程之路</a></span></div><span data-disqus-identifier="2015/05/22/python-beautifulsoup-parse-html-xml/" class="disqus-comment-count"></span><div class="post-content"><p>Python官方文档都说自己解析XML的方式存在漏洞了，那我也只能用他推荐的了。</p>
<p>这里我使用的BeautifulSoup，因为其中文文档十分完整清晰，而且相比于defusedxml，它不仅可以解析XML还可以解析HTML，非常方便。<a href="http://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html" target="_blank" rel="external">文档<br>地址</a></p>
<p>另外，如果是简单的网页解析任务，可以直接将获取到的网页进行正则表达式匹配也可以达到效果，只是可能会出现各种编码各种错误问题</p>
<h2 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h2><pre><code># 直接apt安装
$ sudo apt-get install Python3-bs4  # 这将安装下面两个包

# pip方式安装
$ pip3 install beautifulsoup4   # 这样直接安装或者下载源码进行安装
$ pip3 install lxml             # 如果是解析xml必须安装一个解析器，文档里说的那个解析器只有这个好安装点，需要提前安装好依赖，apt-get install libxml2-dev, libxslt1-dev, python-dev，还可以使用html.parser这个解析器，这个解析器不会自动添加body元素
</code></pre><h2 id="u57FA_u672C_u6982_u5FF5"><a href="#u57FA_u672C_u6982_u5FF5" class="headerlink" title="基本概念"></a>基本概念</h2><p>TAG：表示xml/html里面的一个元素(节点)，包括标签以及其里面的内容</p>
<h2 id="u57FA_u672C_u4F7F_u7528"><a href="#u57FA_u672C_u4F7F_u7528" class="headerlink" title="基本使用"></a>基本使用</h2><p>最简单的使用例子：</p>
<pre><code>import urllib.request
from bs4 import BeautifulSoup


content = &quot;&lt;b&gt;&lt;!--Hey, buddy--&gt;&lt;/b&gt;&quot;   # 表示网页内容
content = urllib.request.urlopen(url)  # 通常做爬虫的时候html来自于网页
soup = BeautifulSoup(content)          # 解析，生成一个bs4.BeautifulSoup
comment = soup.b.string                # 获取&lt;b&gt;标签的内容
</code></pre><h2 id="u67E5_u627E"><a href="#u67E5_u627E" class="headerlink" title="查找"></a><strong> 查找</strong></h2><pre><code># 查找标签
soup.a             # 查找第一个a标签，返回值就是一个TAG&lt;class &apos;bs4.element.Tag&apos;&gt;
soup.find(&apos;a&apos;)     # 同上，都只是查找满足条件的第一个
soup.find_all(&apos;a&apos;) # 查找所有的a标签，返回一个list获取内容
soup.find_all(&apos;a&apos;, class_=&apos;name&apos;)  # 根据标签的属性进行查找，比如这里查找class这个属性为name的a标签
soup.find_all(text=&quot;&quot;) # 在整个文档中查找一个字符串
soup.find_all(&apos;a&apos;, limit=3) # 限制只找三个结果
soup.find_all(&apos;a&apos;, recursive=False) # 只找直接子节点而不递归查找# CSS选择器  



soup.select(&apos;a&apos;) # 查找a标签
soup.select(&apos;.title&apos;) # 查找类为title的标签
soup.select(&apos;#name&apos;)  # 查找id为name的标签
</code></pre><h2 id="u83B7_u53D6_u5185_u5BB9"><a href="#u83B7_u53D6_u5185_u5BB9" class="headerlink" title="获取内容"></a>获取内容</h2><pre><code>tag.name        # 如果是Tag，那么返回它本身，例如，如果是a标签，那就返回a；如果是soup对象，那么返回[document]，返回值都是str类型
tag.attrs       # 获取该标签的属性，返回的是一个字典，例如，如果有个a标签是&lt;a class=&quot;a&quot; href=&quot;#&quot;&gt;&lt;/a&gt;那么返回\{&apos;class&apos;: &apos;a&apos;, &apos;href&apos;: &apos;#&apos;\}
soup.a[&apos;class&apos;] # 直接获取a标签的class属性值
soup.a.get(&apos;class&apos;] # 同上


soup.a.string   # 获取标签内的内容，&lt;a&gt;文字部分&lt;/a&gt;
soup.a.text     # 获取标签内文字部分&lt;span&gt;abc&lt;a href=&quot;&quot;&gt;&lt;/a&gt;&lt;/span&gt; 获取abc
soup.prettify() # 获取所有内容
</code></pre><h2 id="u904D_u5386"><a href="#u904D_u5386" class="headerlink" title="遍历"></a>遍历</h2><p>获取tag内的字符串用tag.string，可以通过unicode方法将NavigableString对象转换成Unicode字符串，如unicode_st<br>ring = unicode(tag.string)</p>
<p>如果要获取xml/html中的注释使用Comment对象，如</p>
<pre><code>markup = &quot;&lt;b&gt;&lt;!--Hey, buddy. Want to buy a used parser?--&gt;&lt;/b&gt;&quot;
soup = BeautifulSoup(markup)
comment = soup.b.string
commment就是注释的东西
print(comment)
&gt;&gt;&gt;u&apos;Hey, buddy. Want to buy a used parser&apos;
可以
print(soup.b.prettify())打印全部&lt;b&gt;
也可以用CDATA替代注释：如
from bs4 import CData
cdata = CData(&quot;A CDATA block&quot;)
comment.replace_with(cdata)


print(soup.b.prettify())
打印：
&lt;b&gt;&lt;![CDATA[A CDATA block]]&gt;&lt;/b&gt;
</code></pre><p>通过点去属性的方式只能获得当前名字的第一个tag，如果要得到所有的就用soup.find_all(‘a’)</p>
<p>tag的.contents属性可以将tag的子节点以列表的方式输出(包括子节点的所有内容)</p>
<pre><code>head_tag = soup.head
head_tag # &lt;head&gt;&lt;title&gt;The Dormouse&apos;s story&lt;/title&gt;&lt;/head&gt;  



head_tag.contents
[&lt;title&gt;The Dormouse&apos;s story&lt;/title&gt;]




title_tag = head_tag.contents[0]
title_tag

#&lt;title&gt;The Dormouse&apos;s story&lt;/title&gt;  



title_tag.contents

[u&apos;The Dormouse&apos;s story&apos;]
</code></pre><p>BeautifulSoup对象本身一定会包含子节点，也就是说<html>标签也是该对象的子节点，如 soup.contents[0].name就是html</html></p>
<p>通过tag的.children生成器，可以对tag的子节点进行循环：</p>
<pre><code>for child in title_tag.children:
    print(child)
    # The Dormouse&apos;s story
</code></pre><p>。desendants属性可以对所有tag的子孙节点进行递归循环</p>
<pre><code>for child in head_tag.descendants:
    print(child)
    # &lt;title&gt;The Dormouse&apos;s story&lt;/title&gt;
    # The Dormouse&apos;s story
字符串也是一个子节点
</code></pre><p>如果tag只有一个NavigableString类型的子节点，就可以用title_tag.string访问子节点</p>
<p>如果tag包含多个字符串就用.strings来循环，如：</p>
<pre><code>for string in soup.strings:
    print(repr(string))
    # u&quot;The Dormouse&apos;s story&quot;
    # u&apos;\\n\\n&apos;
    # u&quot;The Dormouse&apos;s story&quot;
    # u&apos;\\n\\n&apos;
</code></pre><p>使用soup.stripped_strings代替soup.strings可以去掉空白或空行项</p>
<p>父节点就正好相反了，.parent得到父节点，.parents递归得到元素的所有父节点</p>
<p>兄弟节点：.next_sibling，.previous_sibling来访问，通过.next_siblings和.previous_siblings属性对<br>当前节点的兄弟节点迭代输出for sibling in soup.a.next_siblings:这样子</p>
<p>回退和前进：.next_element和.previouw_element，.next_elements和.previous_elements</p>
<p>查找</p>
<p>find和find_all，还可以传入正则表达式，如soup.find_all(re.compile(“^b”))如果传入的是列表，将会与列表中任一元素匹配<br>的内容返回，true可以匹配任何标签，如soup.find_all(True)</p>
<p>检查是否包含属性tag.has_attr(‘class’)</p>
<p>find_all( <a href="http://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh
.html#id32" target="_blank" rel="external">name</a> , <a href="http://www.crummy.com/software/BeautifulSoup/bs4/doc/ind
ex.zh.html#css" target="_blank" rel="external">attrs</a> , <a href="http://www.crummy.com/software/BeautifulSoup/bs4
/doc/index.zh.html#recursive" title="Link:
http://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html#recursive" target="_blank" rel="external">recursive</a> , <a href="http://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html#
text" target="_blank" rel="external">text</a> , <a href="http://www.crummy.com/software/BeautifulSoup/bs4/doc/index.
zh.html#keyword" target="_blank" rel="external">**kwargs</a> )</p>
<p>attr表示具有该属性的name标签，text可以搜索非标签的字符串内容，如soup.find_all(text=”wang”)</p>
<pre><code>soup.find_all(id=&quot;link2&quot;)[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;]
</code></pre><p>limit参数：find_all()方法返回全部的搜索结果，如果文档数很大那么搜索会很慢，如果不需要全部结果，可以用limit参数，类似于SQL中的limi<br>t，如soup.find_all(“a”, limit=2)</p>
<p>如果只搜索直接子节点，就加上recursive=False参数</p>
<p>可以不用指明find_all，如soup.find_all(“a”)可以用soup(“a”)代替，soup.title.find_all(text=True<br>)可以用soup.title(text=True)代替</p>
<p>其他功能，按CSS搜索、支持CSS选择器，支持修改文档树</p>
<p>find()方法至返回一个，其他的还有find_parents()和find_parent()，find_next_siblings()，find_next<br>_sibling()，find_previous_siblings()，find_previous_sibling()，find_all_next()，fi<br>nd_next()，find_all_previous()，find_previous()</p>
<p>如果只想得到tag中包含的文本内容，那么就可以用get_text()方法，获取到tag包含的所有文本内容包括子孙tag中的内容</p>
<p>注：beautifulsoup会自动将tag变为小写，只有添加”xml”选项才能大小写敏感，因为不指定就默认是html，html的标签对大小写不敏感，所以推<br>荐还是把lxml XML解析器安上，不过要先弄上什么C语言库</p>
<h1 id="u4FEE_u6539"><a href="#u4FEE_u6539" class="headerlink" title="修改"></a>修改</h1><pre><code># 删除当前节点
tag.extract()  

# 插入节点
new_tag = &apos;&lt;url&gt;dagasgga&lt;/url&gt;&apos;
new_tag = BeautifulSoup(new_url, &apos;html.parser&apos;)
soup.tag.insert(位置如1, new_tag)
</code></pre></div><a data-url="http://haofly.net/2015/05/22/python-beautifulsoup-parse-html-xml/" data-id="cikhyidfy002xfmrxafgd6k4a" class="article-share-link">分享到</a><div class="tags"></div><div class="post-nav"><a href="/2015/05/29/python-use-redis/" class="pre"><i class="icon-previous">Python Redis模块的使用</i></a><a href="/2015/05/17/laravel-IoC-DI/" class="next">Laravel使用IoC模式(DI、依赖注入)<i class="icon-next"></i></a></div><div id="disqus_thread"><script>var disqus_shortname = 'haoflynet';
var disqus_identifier = '2015/05/22/python-beautifulsoup-parse-html-xml/';
var disqus_title = 'Python使用beautifulsoup解析HTML、XML';
var disqus_url = 'http://haofly.net/2015/05/22/python-beautifulsoup-parse-html-xml/';
(function() {
  var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//haoflynet.disqus.com/count.js" async></script></div></div></div></div><div class="pure-u-1-4"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search" class="search-form-input"/><input type="hidden" name="sitesearch" value="http://haofly.net"/></form></div><div class="widget"><div class="widget-title">分类</div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/就是爱玩/">就是爱玩</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程之路/">编程之路</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/边走边想/">边走边想</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/那时年少/">那时年少</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/韦编三绝/">韦编三绝</a></li></ul></div><div class="widget"><div class="widget-title">最新文章</div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2016/01/06/mysql-update/">MySQL数据库升级过程</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/01/06/mysql-master-slave/">Mysql之主从复制</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/12/30/python-multithreading-multiprocess/">Python多进程和多线程</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/12/17/mysql-migration/">MySQL数据库目录存放位置迁移</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/12/11/design-pattern/">[转]23种设计模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/12/10/mysql-optimization/">MySQL之调优方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/12/10/mysql-design-tips/">MySQL之设计方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/12/08/raspberrypi/">玩转树莓派2</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/12/07/database-application-scenarios/">各种数据库的应用场景</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/12/04/python-requests/">Python Requests模块进行网页抓取详解</a></li></ul></div><div class="widget"><div class="widget-title">最近评论</div><script type="text/javascript" src="//haoflynet.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=1&amp;avatar_size=32&amp;excerpt_length=20&amp;hide_mods=1"></script></div><div class="widget"><div class="widget-title">友情链接</div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div></div><div id="footer">© <a href="/." rel="nofollow">豪翔天下.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/jquery.min.js?v=0.0.0"></script><script type="text/javascript" src="/js/totop.js?v=0.0.0"></script><script type="text/javascript" src="/js/fancybox.pack.js?v=0.0.0"></script><script type="text/javascript" src="/js/jquery.fancybox.js?v=0.0.0"></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?d06802e96e214bdb413a40b263d4cc15";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script><script type="text/javascript" src="/js/share.js?v=0.0.0"></script></div></body></html>